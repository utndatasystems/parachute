{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import utils\n",
    "import duckdb\n",
    "\n",
    "DATA_DIR = 'data/imdb/'\n",
    "\n",
    "schema = utils.read_json(os.path.join(DATA_DIR, 'schema.json'))\n",
    "\n",
    "con = duckdb.connect('dbs/imdb.duckdb', read_only=True)\n",
    "\n",
    "def check(table_size, type, min_val=None, max_val=None, is_nullable=None, null_count=None, distinct_count=None, values=None):\n",
    "  assert null_count is not None\n",
    "  assert distinct_count is not None\n",
    "\n",
    "  # NOTE: `is_nullable` comes from the schema!\n",
    "  if null_count == table_size:\n",
    "    return {\n",
    "      'min' : None,\n",
    "      'max' : None,\n",
    "      '#distinct' : 1,\n",
    "      'is-nullable' : is_nullable,\n",
    "      'has-null' : True,\n",
    "      'only-null' : True\n",
    "    }\n",
    "  if type == 'integer':\n",
    "    return {\n",
    "      'min' : int(min_val),\n",
    "      'max' : int(max_val),\n",
    "      '#distinct' : int(distinct_count),\n",
    "      'is-nullable' : is_nullable,\n",
    "      'has-null' : (null_count != 0),\n",
    "      'only-null' : False\n",
    "    }\n",
    "  elif type == 'varchar' or type == 'char':\n",
    "    return {\n",
    "      'min' : None,\n",
    "      'max' : None,\n",
    "      '#distinct' : int(distinct_count),\n",
    "      'is-nullable' : is_nullable,\n",
    "      'has-null' : (null_count != 0),\n",
    "      'only-null' : False,\n",
    "      'values' : values\n",
    "    }\n",
    "  else:\n",
    "    assert 0\n",
    "    return {}\n",
    "\n",
    "def analyze_col(tn, table_size, col):\n",
    "  print(f'[analyze] {tn} {col}')\n",
    "\n",
    "  type = schema[tn]['columns'][col]['type']\n",
    "  is_nullable = not schema[tn]['columns'][col]['not-null']\n",
    "\n",
    "  # NOTE: `COUNT(DISTINCT column)` does *not* consider NULLs!\n",
    "  # NOTE: However, DISTINCT alone *does* consider NULLs.\n",
    "  if type == 'integer':\n",
    "    ret = con.sql(f\"\"\"\n",
    "      select\n",
    "        MIN({col}) as min_,\n",
    "        MAX({col}) max_,\n",
    "        SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) as null_count,\n",
    "        COUNT(DISTINCT {col}) as distinct_count\n",
    "      from {tn};\n",
    "    \"\"\").df()\n",
    "    min_val = ret['min_'][0]\n",
    "    max_val = ret['max_'][0]\n",
    "\n",
    "    # This is later used to test if we have just NULLs.\n",
    "    null_count = int(ret['null_count'][0])\n",
    "\n",
    "    # NOTE: We also include NULLs here.\n",
    "    # NOTE: However, we decide this only based on the nullable-option, since the current data might not have any NULLs.\n",
    "    distinct_count = ret['distinct_count'][0] + int(is_nullable)\n",
    "    return check(table_size, type, min_val=min_val, max_val=max_val, is_nullable=is_nullable, null_count=null_count, distinct_count=distinct_count)\n",
    "  elif type == 'varchar' or type == 'char':\n",
    "    ret = con.sql(f\"\"\"\n",
    "      select\n",
    "        SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) as null_count,\n",
    "        COUNT(DISTINCT {col}) as distinct_count\n",
    "      from {tn};\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # This is later used to test if we have just NULLs.\n",
    "    null_count = int(ret['null_count'][0])\n",
    "\n",
    "    # NOTE: We also include NULLs here.\n",
    "    # NOTE: However, we decide this only based on the nullable-option, since the current data might not have any NULLs.\n",
    "    distinct_count = ret['distinct_count'][0] + int(is_nullable)\n",
    "\n",
    "    print(distinct_count)\n",
    "\n",
    "    # Collect the unique values.\n",
    "    values = None\n",
    "    if distinct_count + int(is_nullable) <= 256:\n",
    "      values = con.sql(f\"\"\"\n",
    "        SELECT DISTINCT {col} as set\n",
    "        FROM {tn};\n",
    "      \"\"\").df()\n",
    "      values = list(values['set'].values)\n",
    "    return check(table_size, type, is_nullable=is_nullable, null_count=null_count, distinct_count=distinct_count, values=values)\n",
    "  else:\n",
    "    return {}\n",
    "\n",
    "analysis = {}\n",
    "for tn in schema:\n",
    "  table_size = utils.get_table_size(con, tn)\n",
    "  analysis[tn] = { '#size' : int(table_size) }\n",
    "  for col in schema[tn]['columns']:\n",
    "    analysis[tn][col] = analyze_col(tn, table_size, col)\n",
    "\n",
    "# Close the connection.\n",
    "con.close()\n",
    "\n",
    "# utils.print_dict(analysis)\n",
    "\n",
    "utils.write_json(os.path.join(DATA_DIR, 'data-analysis.json'), analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
